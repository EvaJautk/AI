{"cells":[{"cell_type":"code","source":["import pickle\n","import gzip\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy.ndimage import sobel\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","# Load the data\n","def load_data():\n","    path_to_train_data = 'flatland_train.data'\n","    path_to_test_data = 'flatland_test.data'\n","\n","    # Load training data\n","    with gzip.open(path_to_train_data, 'rb') as f:\n","        X_train, y_train = pickle.load(f)\n","\n","    # Load testing data\n","    with gzip.open(path_to_test_data, 'rb') as f:\n","        X_test, y_test = pickle.load(f)\n","\n","    return X_train, y_train, X_test, y_test\n","\n","X, y, X_p, y_p = load_data()\n","\n","# Normalize and convert the data to tensors\n","X = tf.convert_to_tensor(X, dtype=tf.float32) / 255.0\n","X_p = tf.convert_to_tensor(X_p, dtype=tf.float32) / 255.0\n","\n","# Function to apply Sobel edge detection with padding\n","def apply_sobel_edges_with_padding(images, pad_width):\n","    # Pad images\n","    padded_images = tf.pad(images, [[0, 0], [pad_width, pad_width], [pad_width, pad_width]], mode='CONSTANT')\n","\n","    # Define Sobel kernels\n","    sobel_x = tf.constant([[1, 0, -1], [2, 0, -2], [1, 0, -1]], dtype=tf.float32)\n","    sobel_y = tf.constant([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], dtype=tf.float32)\n","\n","    # Reshape kernels to match the expected dimensions for Conv2D\n","    sobel_x = tf.expand_dims(tf.expand_dims(sobel_x, axis=-1), axis=-1)  # Shape: (3, 3, 1, 1)\n","    sobel_y = tf.expand_dims(tf.expand_dims(sobel_y, axis=-1), axis=-1)  # Shape: (3, 3, 1, 1)\n","\n","    # Apply Sobel filters using tf.nn.conv2d\n","    gradient_x = tf.nn.conv2d(padded_images[..., tf.newaxis], sobel_x, strides=[1, 1, 1, 1], padding='VALID')\n","    gradient_y = tf.nn.conv2d(padded_images[..., tf.newaxis], sobel_y, strides=[1, 1, 1, 1], padding='VALID')\n","\n","    # Compute the gradient magnitude\n","    gradient_magnitude = tf.sqrt(tf.square(gradient_x) + tf.square(gradient_y))\n","\n","    return tf.squeeze(gradient_magnitude, axis=-1)\n","\n","# Apply Sobel edge detection\n","pad_width = 1\n","X_edges = apply_sobel_edges_with_padding(X, pad_width)\n","X_p_edges = apply_sobel_edges_with_padding(X_p, pad_width)\n","\n","# Add channel dimension to the edge-detected images\n","X_edges = np.expand_dims(X_edges, axis=-1)\n","\n","# Data augmentation\n","train_datagen = ImageDataGenerator(\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","train_datagen.fit(X_edges)\n","\n","# Split data into train and test sets\n","x_train, x_test, y_train, y_test = train_test_split(X_edges, y, test_size=0.2, random_state=42)\n","\n","# Build the model\n","model = keras.Sequential()\n","model.add(layers.Input(shape=(52, 52, 1)))\n","\n","# Define filter sizes and dropout rates for each layer\n","layer_configs = [\n","    {\"filters\": 16, \"dropout\": 0.2},\n","    {\"filters\": 32, \"dropout\": 0.3},\n","    {\"filters\": 64, \"dropout\": 0.4},\n","    {\"filters\": 128, \"dropout\": 0.5}\n","]\n","\n","# Add convolutional layers in a loop\n","for config in layer_configs:\n","    model.add(layers.Conv2D(config[\"filters\"], (3, 3), activation='relu'))\n","    model.add(layers.BatchNormalization())\n","    model.add(layers.MaxPooling2D((2, 2)))\n","    model.add(layers.Dropout(config[\"dropout\"]))\n","\n","# Fully connected layers\n","model.add(layers.Flatten())\n","model.add(layers.Dense(128, activation='relu'))\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(10, activation='softmax'))\n","\n","# Compile model\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Custom Callback for Printing Epoch Info\n","class CustomEpochLogger(keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs=None):\n","        accuracy = logs.get('accuracy')\n","        loss = logs.get('loss')\n","        print(f'Epoch {epoch + 1}: accuracy: {accuracy:.4f}, loss: {loss:.4f}')\n","\n","# Model checkpointing\n","checkpoint_callback = ModelCheckpoint(\n","    filepath='model_best.weights.h5',  # Ensure the filename ends with `.weights.h5`\n","    monitor='val_accuracy',\n","    save_best_only=True,\n","    save_weights_only=True,\n","    verbose=0  # Suppress model saving output to keep the desired output format\n",")\n","\n","# Train the model\n","train_generator = train_datagen.flow(\n","    x_train,\n","    y_train,\n","    batch_size=32,\n","    shuffle=True\n",")\n","\n","model.fit(\n","    train_generator,\n","    epochs=55,  # Set the desired number of epochs\n","    validation_data=(x_test, y_test),\n","    callbacks=[checkpoint_callback, CustomEpochLogger()],  # Use both callbacks\n","    verbose=0  # Suppress default epoch logging\n",")\n","\n","# Evaluate the model\n","test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n","print(f'\\nTest accuracy: {test_accuracy:.4f}')\n","\n","# Predict on X_p_edges and display predictions\n","X_p_edges = np.expand_dims(X_p_edges, axis=-1)\n","predictions = model.predict(X_p_edges)\n","predicted_labels = [np.argmax(pred) for pred in predictions]\n","formatted_predictions = ''.join([str(round(p)) for p in predicted_labels])\n","print(\"Predicted labels:\", formatted_predictions)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1v5xE6mmHqH5","executionInfo":{"status":"ok","timestamp":1730139176391,"user_tz":-120,"elapsed":1206309,"user":{"displayName":"Eva J.","userId":"10283767594580959022"}},"outputId":"062ff348-1f73-4b53-b81e-e6d979fce31e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1: accuracy: 0.2661, loss: 2.0876\n","Epoch 2: accuracy: 0.3385, loss: 1.5459\n","Epoch 3: accuracy: 0.4027, loss: 1.3711\n","Epoch 4: accuracy: 0.4538, loss: 1.2565\n","Epoch 5: accuracy: 0.4978, loss: 1.1455\n","Epoch 6: accuracy: 0.5414, loss: 1.0644\n","Epoch 7: accuracy: 0.5846, loss: 0.9861\n","Epoch 8: accuracy: 0.6166, loss: 0.9219\n","Epoch 9: accuracy: 0.6499, loss: 0.8583\n","Epoch 10: accuracy: 0.6714, loss: 0.8153\n","Epoch 11: accuracy: 0.6940, loss: 0.7740\n","Epoch 12: accuracy: 0.7176, loss: 0.7320\n","Epoch 13: accuracy: 0.7398, loss: 0.6898\n","Epoch 14: accuracy: 0.7606, loss: 0.6437\n","Epoch 15: accuracy: 0.7814, loss: 0.6195\n","Epoch 16: accuracy: 0.7856, loss: 0.5917\n","Epoch 17: accuracy: 0.7991, loss: 0.5677\n","Epoch 18: accuracy: 0.8076, loss: 0.5504\n","Epoch 19: accuracy: 0.8246, loss: 0.5174\n","Epoch 20: accuracy: 0.8263, loss: 0.5226\n","Epoch 21: accuracy: 0.8339, loss: 0.4940\n","Epoch 22: accuracy: 0.8450, loss: 0.4730\n","Epoch 23: accuracy: 0.8509, loss: 0.4649\n","Epoch 24: accuracy: 0.8561, loss: 0.4516\n","Epoch 25: accuracy: 0.8533, loss: 0.4548\n","Epoch 26: accuracy: 0.8612, loss: 0.4340\n","Epoch 27: accuracy: 0.8689, loss: 0.4242\n","Epoch 28: accuracy: 0.8640, loss: 0.4247\n","Epoch 29: accuracy: 0.8720, loss: 0.4045\n","Epoch 30: accuracy: 0.8792, loss: 0.4086\n","Epoch 31: accuracy: 0.8755, loss: 0.4086\n","Epoch 32: accuracy: 0.8827, loss: 0.3901\n","Epoch 33: accuracy: 0.8854, loss: 0.3816\n","Epoch 34: accuracy: 0.8859, loss: 0.3731\n","Epoch 35: accuracy: 0.8926, loss: 0.3676\n","Epoch 36: accuracy: 0.8911, loss: 0.3653\n","Epoch 37: accuracy: 0.8951, loss: 0.3511\n","Epoch 38: accuracy: 0.9003, loss: 0.3466\n","Epoch 39: accuracy: 0.8935, loss: 0.3552\n","Epoch 40: accuracy: 0.9025, loss: 0.3424\n","Epoch 41: accuracy: 0.8982, loss: 0.3448\n","Epoch 42: accuracy: 0.9056, loss: 0.3327\n","Epoch 43: accuracy: 0.9047, loss: 0.3373\n","Epoch 44: accuracy: 0.9101, loss: 0.3189\n","Epoch 45: accuracy: 0.9060, loss: 0.3298\n","Epoch 46: accuracy: 0.9093, loss: 0.3157\n","Epoch 47: accuracy: 0.9134, loss: 0.3104\n","Epoch 48: accuracy: 0.9109, loss: 0.3158\n","Epoch 49: accuracy: 0.9082, loss: 0.3207\n","Epoch 50: accuracy: 0.9156, loss: 0.3112\n","Epoch 51: accuracy: 0.9166, loss: 0.3159\n","Epoch 52: accuracy: 0.9111, loss: 0.3140\n","Epoch 53: accuracy: 0.9166, loss: 0.3050\n","Epoch 54: accuracy: 0.9166, loss: 0.3039\n","Epoch 55: accuracy: 0.9199, loss: 0.2953\n","\n","Test accuracy: 0.9850\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step\n","Predicted labels: 6645533343400063340545465645540463050355660333004303364366664054553303655503043350530664600355355463530403365345345040035360650004655530445455543654345046545635635636546303536656366660360305666463536336363336336465353306053566453360450054500063445060346643400453633456446546354503346300344553655053533306444055363443403030604300064655506334560544330054354500443044350645463346060306564305653645045350533336636330660644345564354536003644433663304055544504505345553050664300303444544504030306344006554333400506036544330334035643434343650403330363543435603566463440550643403430450565505303434536654355435035004453066464566036403330463450364406563043554443345350563053566660564533336350334356344353343060333043443433504546433334036630044450544503643600503355633656300553303033036463444460546453433660605604345456536403330035505464066564430553033365340544530633643635653364030035430440356534344063556033036433354560635036440504640055344340360630645656404363635646435404000566355305364603035300453665355604454560366065300453055344643054505003540633033300355366455363044363454665305346550453446603355040336344366406566034430635645460030055644643436454555666535604534433533403556463455534635504300045363464434440365505440353066633435455505544440035566563444365006465334333654054465343003434466346465433440434444330364534565056636553350466366665444065035404305464055003066363646443506034056346345655363030563036546534303465653566303600330536353436333434335066330534556336543636533063664463644460404363630444655330334564353535300043333343453445064635566334303000404403305345440056456054646036363046453663443444334334364535344333565433446553504546563640503053635560330536553405563434335030303564065630335564353604646660446546334656646034645633405050533554434534053504534405566040353534050034445565535546605453535630533063453436563543544605056506040536044436563044440033640300305503465030335635304543503564033033543435664056553346400556563443446463556044360306553306600055344056563654053560300666335553436354636400330664340433345565444300563355536004040300400065555046565654663363660654645500503003630650436003654440605564505646630346355433505630004404465444333403544403353305434636435445550503645406353043335346063545366004536604054343043033336453304430466340456433534534536333403355666553334454634033053654043354460530650536533346333434535463464434035503535343436364653634550440500435666345606454665640553644340635346054344304443504645543556060034444434435605505646056505054364430550453306065566635536005634355634443355443436333404335360534644440440545463535040636333636444354445040543006605653655360446635564036306434533006445444004534466356330350345040343305300544054345636344534604554430666300406443045344343330335336056053464306403345334506006634436303345550653600450654463633334506505030605464635403660364436456553634040053405653564645635345450353400465565535430003533063334533606646403603630434654540343400453654430433000355606550305343654336630366533660345044400350004444543035603563050306033344665435655030343536346556005546533663560360430535500665336003655054633553303006404450450634554536533463300535503360036660060405034434454335060446450303343443056545544330343330055464646043364344636436445334043030353350433055033603455534653363030644354304633634536330666330045505005663635345635334344404364433445505543543504363456364430445430535344605443000655533404304563404640665353000035505645536635353336400044460044504306453444053003540444443605544643530663430364663560334463546064033535564663345340034036465533560355556644334504445356446435043330000534403446344565465064664063655546055533536530460566530553366043363553453456305045534303640053455366366565536434064604033444343434050564556356435335343633056430044454646560054446633606044356563444330444403453356403504340435330335464553365063505053666400503343035363405346543530544463644305400303650645653340666304453636660043403354334663064500044040500435660540656663334434330336363453544360300366304455653446334043305004353335654660606335543340534444563060645650564536434443463400404005455505436460500000063443330560564665363305643355000563435365655645656433406335063566553500653635654630534444345055343545305666664644306463400036046463034550033543340354543564563603564656055403630566030534404035343554053034363044364045365544355303463566306545363406335534546646653500550646504344500345435643030505536343436300363643530353436606330535535304635565464054634506555366353545345356400430305533654000345360535005643063443654636635650630534606340066305304566354633455355455503600054533434356446356440350530650453503444430334353043044603354035330305450533640405355666543060563433333663636354435463033530043635356430066600034363434554334333065006330554643463563440005464440305003046440443634503300000633634654433533665505665343540005454463634435034463446603640555543540533344640433530543355406440604656644404605530003653553300653533334050334644403000464446460453606646504355350553343646335604355344405540443303500303655540656333503345330533455454450036666053604334340533036436336553535630550563343006003330555604503650663344663353444343653450356546335533503654563304506665535636306444056464403445466556453534336536440406656533060344640545544403630555336443430440603353034634556566344464343330053634304340666403044333433450643535530554563303565553304360336430335065665366063533003460635034533643053064540066036360355364434403564433444643653546504430646436035564633456530303564346033503636400004563555304646663433053043636330443444434545345353456343360363635030063464036330665043460505456545343400653406403335555056043040504443034063506000333653004635035644500656303030065603630653035054303056460454534033540465335333565453554563046305405444433564554604563334034644435660463463063500334600045334336050344466654053533004446555543553633656640334605336503056633463644006663534363303406344503035354304433604636333345630035066355354333003344645665445540045440564543500305553344056334545404344365605546040055334635300654304564403405530555534306344666035536040454454454436343564066633305646650543634053335334450346434300360600534655040034065403404555303435534306645354344665640066354334000550353503650003546535350346350400553433650660034343635030336335564364334536654443540044035303306360554344433033443364443033605035353440336404453306045063060603036503644055540464463055550545444333065544403534354655356400640354460050465545363344350043656055435356634033045360365653505054350435656634436604333433530533363636043000634404656330605033035055345664346634436553363436656453433363543404503443454456645363344340505304503036030553363000633054430503045304005335335340366333430463654055443006544053550346363034035353544044553030334305466364063434460554506643556536343006544030365546560005356333453533003404553354035430466444034553606435543303606665035443353633353366300366536055446456430533333564440554336533353455503665365645400400534054630634306653646560044540456345533434634654536545360355436350633450635445333506563656464364643446356343355635663503560450644446543335604443546033454333400303666665060360350365044034645664400456434534566640536065430463504033443546044300363455345635464350666454450636440355546036350366400645365356404344450453635364353634043650305033063545363046606356355604330543604063466644305533353665333464333354663034354645433345356404404556040406434544454345464333645530336500050535433433630464536335550556636504340045344356466666665034350063335553505430456604346346334443665535660354444543440436406046000654564446436305335544355455343303333345446563453530534653465306650333534053335056336304304000060055640654053344000456644640504066063660543303630503034660036544435364054544663065434033533360406443565306634656534560043343563363656444456064540304650550345606004403606046455653433636355533330303005433456405563556303330534535665005666300366345365004433443540543066530004554664344055436333553344345063634064050634356006506443645446366333333065346665050603665335044366534444050063546304463335643530343343006033545443646653665406655454353435545403605353303536300303455305604463503306500036656530354004364545643440403360303066460443450044534633440603650306364346536435433464464433455000336334504465646643343430405433655534554434430460334463043030644433440334640630346064304443403544533436636563455064443633645633550035304403544045303633604436530403604363550443560300443660340655356450346533003335033366453455545443366460440534430645530346303456645434036360304346305034406003344456003006330665660646033545300463460364403453056534534533300330044640535665555554033505360334500405343464404635565655465503464555554030430005665306334660333036465644500643004460335653563304344034430304635434033303304405454663645064043033430045064550056634453300036344646636436335655565445354053640643034350665333366445650605464503305063353430443043563500553363343565335555654003556660353346400030554033300563036353664455033540463305646453460063600500454363656555364363303604665664363555004440336066640364504530634446446544335664646304033046344355433356633530363444333340353355005606565560435364053556360466006436450436034465430356350546445333534335345033334433063444300534443536600505304650556404454555663545454053033340363045430536056443555454530546005635343664004033543644033560035666556643630604345633004543354034435355345303633564433650654530006366653034653030034340446566604334663366344354453066603034330333530630003533634305350000004554046065404306553443504300635036560663465355645633345663436000445066605333033064453656303666364360666536306335444356354553650666340344505355550466503403455363646055545003033343433440353506633344665405455636056036400305646033553303345305365503466306334436533555006053634453443345035344340636030505463055036333045454000354630655450354430453346455030656535400434350533446035060346545343506646636355033360436054466046305450455444555456543030556344335050003464633630643444030634546404500603046365004036353554506650550504554500350604344634543445334406306366454450454545050655603364046533354654633433440564455444306653000606446605333644035433406430635\n"]}]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"19FYE_zSuAh37RN-sT7H_R7br8Vtqyk6R","authorship_tag":"ABX9TyOGeFU6oIgFUIrg6SqcMOlg"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}